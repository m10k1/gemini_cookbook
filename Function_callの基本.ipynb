{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfobUwAbp3pG1zf1YuwYfV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m10k1/gemini_cookbook/blob/main/Function_call%E3%81%AE%E5%9F%BA%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ｇｅｍｉｎｉ ＡＰＩ: ＰｙｔｈｏｎによるＦｕｎｃｔｉｏｎ コール\n",
        "\n",
        "Ｆｕｎｃｔｉｏｎコールとは、開発者がＬＬＭに向けてコード内にある関数の説明文を作るようなものです。\n",
        "\n",
        "ＬＬＭからの応答に説明文に該当する関数名とその引数が含まれて返ってきます。\n",
        "\n",
        "Ｆｕｎｃｔｉｏｎコールは生成ＡＩアプリケーションで関数を使えるようにするための仕組みで、一つのリクエストで複数の関数を定義できます。\n",
        "\n",
        "このノートブックではＦｕｎｃｔｉｏｎコールの基本的な使い方を学びます。\n",
        "\n",
        "## セットアップ\n",
        "\n",
        "pipモジュールを追加します"
      ],
      "metadata": {
        "id": "94UU_ihXuzbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o0N2UTP8wdy4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "krQcke6PuyZu"
      },
      "outputs": [],
      "source": [
        "! pip install -qU google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Keyの設定\n",
        "\n",
        "ＧｅｍｉｎｉのＡＰＩを利用するにはＡＰＩキーを使用する必要があります。"
      ],
      "metadata": {
        "id": "zEb2O2K6weoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# クライアントオブジェクトの作成\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kf41RD5WwdB7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルの選択\n",
        "\n",
        "ＧｅｍｉｎｉモデルはＦｕｎｃｔｉｏｎコールが利用できます。"
      ],
      "metadata": {
        "id": "5K-nhQBmxGBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.5-flash\" #@param [\"gemini-2.5-flash-lite\", \"gemini-2.5-flash-lite-preview-09-2025\", \"gemini-2.5-flash\", \"gemini-2.5-flash-preview-09-2025\", \"gemini-2.5-pro\"] {\"allow-input\":true, isTemplate: true}\n"
      ],
      "metadata": {
        "id": "n8V2JAm0xOZg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ツールとして関数を設定する\n",
        "\n",
        "Ｆｕｎｃｔｉｏｎコールを使うには、GenerativeModelを作成する際のtoolsパラメータに関数のリストを渡します。\n",
        "\n",
        "モデルは、関数名、docstring, パラメータ、パラメータの型アノテーションを使ってプロンプトの解答するのに関数が必要かどうかを判断します。\n",
        "\n",
        "> **重要**: ＳＤＫは関数パラメーターの型アノテーションをＡＰＩの様式に変換します（genai.types.FunctionDeclaration)。\n",
        "> Python SDKの自動変換は次の型をサポートする。\n",
        "AllowedTypes = int | float | bool | str | list['AllowdTypes']\n",
        "\n",
        "**例: 照明システムの関数**\n",
        "\n",
        "仮想照明システムを制御する3つの関数です。docstringと型のヒントに注意してください"
      ],
      "metadata": {
        "id": "lDvfiVSnxkzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enable_lights():\n",
        "  \"\"\"照明を点灯します\"\"\"\n",
        "  print(\"LIGHTBOT: Lights enabled.\")\n",
        "\n",
        "def set_light_color(rgb_hex: str):\n",
        "  \"\"\"照明の色を設定する。照明が点灯していなければならない\"\"\"\n",
        "  print(f\"LIGHTBOT: Lights set to {rgb_hex}\")\n",
        "\n",
        "def stop_lights():\n",
        "  \"\"\"照明を消灯します\"\"\"\n",
        "  print(\"LIGHTBOT: 照明を消しました\")\n",
        "\n",
        "light_controls = [enable_lights, set_light_color, stop_lights]\n",
        "\n",
        "instruction = \"\"\"\n",
        "あなたは便利な照明システムです。\n",
        "照明を点灯したり消灯したりすることができます。そして照明の色も設定することができます。\n",
        "それ以外の振る舞いは行わないこと\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "G1rUF04FzuZy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## チャットでのＦｕｎｃｔｉｏｎコールの基本\n",
        "\n",
        "バックグラウンドで何が起こったかを理解するには、チャット履歴を調べることができます。\n",
        "\n",
        "Chat.historyプロパティには、ユーザとGeminiモデルの会話の時系列記録が保存されます。Chat.get_history()を使って履歴を取得できます。会話の各ターンは、以下の情報を含むgenai.types.Contentオブジェクトで表されます：\n",
        "\n",
        "Role: コンテンツの発信元が \"user \"か \"model \"かを識別します。\n",
        "\n",
        "パーツ： メッセージの個々のコンポーネントを表すgenai.types.Partオブジェクトのリスト。テキストのみのモデルでは、これらのパーツは以下のようになります：\n",
        "\n",
        "テキスト： テキストメッセージ。\n",
        "関数呼び出し（genai.types.FunctionCall）： 与えられた引数で特定の関数を実行するモデルからのリクエスト。\n",
        "関数レスポンス(genai.types.FunctionResponse): 関数実行後にユーザが返す結果： リクエストされた関数を実行した後にユーザが返す結果。"
      ],
      "metadata": {
        "id": "LvY7y8Ce2ZgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config = {\n",
        "        \"tools\": light_controls,\n",
        "        \"system_instruction\": instruction,\n",
        "    }\n",
        ")\n",
        "\n",
        "response = chat.send_message(\"ここの部屋は暗すぎる\")\n",
        "\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHKh5MSP3ieV",
        "outputId": "ce3d6fea-81bb-46b8-fcc0-62e59765b423"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIGHTBOT: Lights enabled.\n",
            "部屋の照明を点灯しました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ｆｕｎｃｔｉｏｎコールの実行と履歴の調査\n",
        "\n",
        "背後で何が起こっているのかを理解するために、チャットの履歴を調査することができます。\n",
        "\n",
        "Chat.historyプロパティは時間軸順でユーザーとモデルの会話のレコードが保存されています。Chat.get_history()を使って履歴を取得できます。\n",
        "各会話のターンはgenai.types.Contentオブジェクトで表現されます。\n",
        "Contentオブジェクトには次の情報が含まれます。\n",
        "\n",
        "* Role: コンテンツがuserからのものか、modelからのものか識別\n",
        "* Parts: メッセージの個々のコンポーネントのgenai.types.Partオブジェクト\n",
        "  - **Text**: プレーンテキスト\n",
        "  - **Function Call(genai.typesFunctionCall)**: モデルからの関数実行の要求。\n",
        "  - **Function Response(genai.types.FunctionResponse)**: 要求された関数の実行後にユーザーから戻す結果\n",
        "  "
      ],
      "metadata": {
        "id": "3ZV6Xn88C_fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "def print_history(chat):\n",
        "  print('print_history')\n",
        "  for content in chat.get_history():\n",
        "    display(Markdown(\"###\" + content.role + \":\"))\n",
        "    for part in content.parts:\n",
        "      if part.text:\n",
        "        display(Markdown(part.text))\n",
        "      if part.function_call:\n",
        "        print(f\"Functional call: {part.function_call}\")\n",
        "      if part.function_response:\n",
        "        print(f\"Function response: {part.function_response}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print_history(chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "VDDHxHl3LTOb",
        "outputId": "30940efb-d6ab-42d3-d0b5-d0a0e1dd9845"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "print_history\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ここの部屋は暗すぎる"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={} name='enable_lights'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='enable_lights' response={'result': None}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "部屋の照明を点灯しました。"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ユーザーが入力した「ここの部屋は暗すぎる」というメッセージに対して\n",
        "モデルは、Ｆｕｎｃｔｉｏｎコールを応答で返してきています。\n",
        "Ｆｕｎｃｔｉｏｎコールで指定された関数名は、「enable_lights」で、ライトを点ける判断を行っていることが分かります。\n",
        "\n",
        "ユーザー側ではＳＤＫによりChatSessionが自動的に実行されてenable_lights()が実行されます。automatic_function_callingが有効になっているため。\n",
        "\n",
        "モデルは結果として、\"部屋の照明を点灯しました。\"を返します。\n",
        "\n",
        "## 自動ファンクション実行（Python SDKの機能)\n",
        "\n",
        "上記で示したように、Python SDKのChatSessionには自動関数実行という強力な機能があります。有効にすると（デフォルトです）、モデルがFunctionCallで応答した場合、SDKは次のことを行います：\n",
        "\n",
        "1. 提供されているツールから対応するPython関数を検索します。\n",
        "\n",
        "2. モデルによって提供された引数で関数を実行します。\n",
        "\n",
        "3. 関数の戻り値をFunctionResponseでモデルに返します。\n",
        "\n",
        "4. モデルの最終レスポンス（通常はテキスト）のみをコードに返します。\n",
        "\n",
        "これにより、一般的なユースケースのワークフローが大幅に簡素化されます。\n",
        "\n",
        "**例：数学オペレーション**\n"
      ],
      "metadata": {
        "id": "9ntlYEy8OoO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "def add(a: float, b: float):\n",
        "  \"\"\"a + b の計算結果を返します\"\"\"\n",
        "  return a + b\n",
        "\n",
        "def subtract(a: float, b:float):\n",
        "  \"\"\"a - b の計算結果を返します\"\"\"\n",
        "  return a - b\n",
        "\n",
        "def multiply(a: float, b: float):\n",
        "  \"\"\"a * b  の計算結果を返します\"\"\"\n",
        "  return a * b\n",
        "\n",
        "def divide(a: float, b:float):\n",
        "  \"\"\"a / b の計算結果を返します\"\"\"\n",
        "  return a / b\n",
        "\n",
        "operation_tools = [add, subtract, multiply, divide]\n",
        "\n",
        "chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config={\n",
        "        \"tools\": operation_tools,\n",
        "        \"automatic_function_calling\": {\"disable\": False}\n",
        "    }\n",
        ")\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"私は57匹の猫を飼っていて、それぞれ44個のミトンを持っています。全部でいくつのミトンがありますか\"\n",
        ")\n",
        "\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQhsSc3leMIp",
        "outputId": "44ec6bbc-1e9c-46d8-9f58-631166099ddc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2508個のミトンがあります。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_history(chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "XCSh88x1gMtb",
        "outputId": "a639d2d0-e5cf-4564-81df-4038a8049958"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "print_history\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "私は57匹の猫を飼っていて、それぞれ44個のミトンを持っています。全部でいくつのミトンがありますか"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'b': 44, 'a': 57} name='multiply'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='multiply' response={'result': 2508}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "2508個のミトンがあります。"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 自動関数スキーマ宣言\n",
        "\n",
        "Python SDKの主な利便性は、Python関数から必要なFunctionDeclarationスキーマを自動的に生成する機能です。これは\n",
        "\n",
        "* 関数名： (func.__name__)\n",
        "\n",
        "* Docstring： 関数の説明に使用されます。\n",
        "\n",
        "* パラメータ： 名前と型のアノテーション（int、str、float、bool、list、dict）。Google styleのような特定の書式を使用している場合）パラメータのDocstringは、説明を強化することもできます。\n",
        "\n",
        "* 戻り値の型のアノテーション： 厳密にどの関数を呼び出すかを決定するためにモデルが使うわけではありませんが、良い習慣です。\n",
        "\n",
        "一般的に、Python関数をツールとして直接使用する場合、FunctionDeclarationオブジェクトを手動で作成する必要はありません。\n",
        "\n",
        "しかし、スキーマを検査したり、修正したり、Python関数オブジェクトをすぐに利用できないシナリオで使用する必要がある場合は、genai.types.FunctionDeclaration.from_callableを使用して明示的にスキーマを生成することができます。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T4a5qgI7gRQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "set_color_declaration = types.FunctionDeclaration.from_callable(\n",
        "    callable = set_light_color,\n",
        "    client = client\n",
        ")\n",
        "\n",
        "print(json.dumps(set_color_declaration.to_json_dict(), indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZXsSMcfiANS",
        "outputId": "4bd34189-0f78-458f-b416-aa82f10fd85f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"description\": \"\\u7167\\u660e\\u306e\\u8272\\u3092\\u8a2d\\u5b9a\\u3059\\u308b\\u3002\\u7167\\u660e\\u304c\\u70b9\\u706f\\u3057\\u3066\\u3044\\u306a\\u3051\\u308c\\u3070\\u306a\\u3089\\u306a\\u3044\",\n",
            "    \"name\": \"set_light_color\",\n",
            "    \"parameters\": {\n",
            "        \"properties\": {\n",
            "            \"rgb_hex\": {\n",
            "                \"type\": \"STRING\"\n",
            "            }\n",
            "        },\n",
            "        \"required\": [\n",
            "            \"rgb_hex\"\n",
            "        ],\n",
            "        \"type\": \"OBJECT\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## マニュアルＦｕｎｃｔｉｏｎコール\n",
        "\n",
        "よりコントロールするため、あるいは自動関数呼び出しが利用できない場合、モデルからのgenai.types.FunctionCallリクエストを自分で処理することができます。以下のような場合です：\n",
        "\n",
        "* デフォルトの \"automatic_function_calling \"でChatを使用している場合： {disable\"： True}を使用している。\n",
        "* Client.model.generate_contentを使用している（そしてチャット履歴を自分で管理している）。\n",
        "\n",
        "例 映画\n",
        "\n",
        "以下の例は、Pythonでシングルターンのcurlサンプルを呼び出す関数に大まかに相当します。おそらく仮想的なAPIから、映画の再生時間情報を（モックとして）返す関数を使用しています：\n"
      ],
      "metadata": {
        "id": "Cz11vGEOiOs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_movies(description: str, location: str):\n",
        "    \"\"\"任意の説明、ジャンル、タイトルの単語などに基づいて、現在映画館で上映されている映画のタイトルを検索します。\n",
        "\n",
        "    Args:\n",
        "        description: カテゴリーやジャンル、タイトル語、属性など、あらゆる種類の説明文\n",
        "        location: 都市と州（例：カリフォルニア州サンフランシスコ、郵便番号：95616など\n",
        "    \"\"\"\n",
        "    return [\"Barbie\", \"Oppenheimer\"]\n",
        "\n",
        "\n",
        "def find_theaters(location: str, movie: str):\n",
        "    \"\"\"場所と、現在上映中の映画のタイトルから映画館を検索。\n",
        "    Find theaters based on location and optionally movie title which are currently playing in theaters.\n",
        "\n",
        "    Args:\n",
        "        location: 都市と州（例：カリフォルニア州サンフランシスコ、郵便番号：95616など\n",
        "        movie: 映画のタイトル\n",
        "    \"\"\"\n",
        "    return [\"Googleplex 16\", \"Android Theatre\"]\n",
        "\n",
        "\n",
        "def get_showtimes(location: str, movie: str, theater: str, date: str):\n",
        "    \"\"\"\n",
        "    特定の劇場で上映される映画の開始時間を検索します。\n",
        "\n",
        "    Args:\n",
        "      location: 都市と州（例：カリフォルニア州サンフランシスコ、郵便番号：95616など\n",
        "      movie: 映画のタイトル\n",
        "      thearer: 劇場名\n",
        "      date: 開演希望日\n",
        "    \"\"\"\n",
        "    return [\"10:00\", \"11:00\"]\n",
        "\n",
        "theater_functions = [find_movies, find_theaters, get_showtimes]"
      ],
      "metadata": {
        "id": "v9Ve18yQiOR5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"カリフォルニア州マウンテンビューでバービーの映画を上映している映画館は？\",\n",
        "    config = {\n",
        "        \"tools\": theater_functions,\n",
        "        \"automatic_function_calling\": {\"disable\": True}\n",
        "    }\n",
        ")\n",
        "\n",
        "print(json.dumps(response.candidates[0].content.parts[0].to_json_dict(), indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JQVa9MUiaOR",
        "outputId": "0be46562-34d1-40dc-a530-017364f9996b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"thought_signature\": \"CqgDAdHtim_0o3DeEShO-hIN-toVw26NChscqHS7LRARchGMjJbQoR1Vzg3kgwMqaK4NvumvMr2yf-8K9a784gPeDFiX65DUJJ90sp9JSBrRYGEwm0hrTLrbo-zCX5m-i23JsHASEXT1PLCae-0es76IlHuW9m-5GyT51w8m3O3JgIe625LLpSnrgJQ3J-dcJUCIftT0D1K_FabUWrabkg_mRcshTOKn7CIeoELAyoWQ6UME4iD2AJLebV182Rj56cgdIS-XxKwI1Z852_HYsWdBjvmsYompjEZ5_CSB3FQNZB1BU7nJGbN-fb0GJCnYe4R8eMxv5fgBp-AYhrj4SDAePoKC5vxDLYIqX0QwcWJhXEoqqslarft2jupFX6YBdzbxGTZv0MOp5tczpYROqs1s0GdVh5lyRanOT9rPMMD9wbvQ_3OZPojHRQGiL1bYPuR_VsqgksP5XELMd1WuNGSDvt_FRgR_FWA9yVqQ_heMbJWTLXLZIMpNWQSgqBXFaSTmGDjufOKdltGFvnpieoXzc79dgID4_LdsqKvlBwDt6VciDvfvG3117w==\",\n",
            "    \"function_call\": {\n",
            "        \"args\": {\n",
            "            \"location\": \"Mountain View, California\",\n",
            "            \"movie\": \"Barbie\"\n",
            "        },\n",
            "        \"name\": \"find_theaters\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "これは自動関数呼び出しの ChatSession を使用していないので、自分で関数を呼び出す必要があります。\n",
        "\n",
        "これを行う非常に簡単な方法は if 文です：\n",
        "\n",
        "if function_call.name == 'find_theaters'：\n",
        "  find_theaters(**function_call.args)\n",
        "elif ...\n",
        "しかし、あなたはすでにtheater_functionsリストを作っているので、これは次のように単純化できる："
      ],
      "metadata": {
        "id": "FFJLrS6BlHcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_function(function_call, functions):\n",
        "    function_name = function_call.name\n",
        "    function_args = function_call.args\n",
        "    # Find the function object from the list based on the function name\n",
        "    for func in functions:\n",
        "        if func.__name__ == function_name:\n",
        "            return func(**function_args)\n",
        "\n",
        "part = response.candidates[0].content.parts[0]\n",
        "\n",
        "# Functionコールかどうか確認。 実際の処理ではモデルの応答内容に応じてテキストを処理する必要がある\n",
        "# .\n",
        "if part.function_call:\n",
        "    result = call_function(part.function_call, theater_functions)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H2X5UXPlNDo",
        "outputId": "01c259f3-e2b8-4c88-9f2c-7bcfa584e451"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Googleplex 16', 'Android Theatre']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "最後に、モデルから最終的なテキストレスポンスを取得するために、レスポンスとメッセージ履歴を次の generate_content() 呼び出しに渡します。次のコードセルでは、Contentを書き出すさまざまな方法を示しています。"
      ],
      "metadata": {
        "id": "nexl6eemlrbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "# Build the message history\n",
        "messages = [\n",
        "    types.Content(\n",
        "        role=\"user\",\n",
        "        parts=[\n",
        "            types.Part(\n",
        "                text=\"Which theaters in Mountain View show the Barbie movie?.\"\n",
        "            )\n",
        "        ]\n",
        "    ),\n",
        "    types.Content(\n",
        "        role=\"model\",\n",
        "        parts=[part]\n",
        "    ),\n",
        "    types.Content(\n",
        "        role=\"tool\",\n",
        "        parts=[\n",
        "            types.Part.from_function_response(\n",
        "                name=part.function_call.name,\n",
        "                response={\"output\":result},\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "]\n",
        "\n",
        "# Generate the next response\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=messages,\n",
        "    config = {\n",
        "        \"tools\": theater_functions,\n",
        "        \"automatic_function_calling\": {\"disable\": True}\n",
        "    }\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZOxDyxumMCN",
        "outputId": "b290ea00-2fb2-493d-99ba-d6c59790742d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "「バービー」を上映しているマウンテンビューの映画館は、Googleplex 16とAndroid Theatreです。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 並列なファンクションコール\n",
        "\n",
        "Gemini APIは、1つのターンで複数の関数を呼び出すことができる。これは、タスクを完了させるために複数の関数呼び出しが独立して行われるシナリオに対応する。\n",
        "\n",
        "まず、ツールをセットアップする。上記の映画の例とは異なり、これらの関数は呼び出されるために互いからの入力を必要としないので、並列呼び出しの良い候補となるはずである。\n"
      ],
      "metadata": {
        "id": "Gsmq7MWZmSBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def power_disco_ball(power: bool) -> bool:\n",
        "    \"\"\"回転するディスコボールを動かす。\"\"\"\n",
        "    print(f\"ディスコボール {'スピンしています!' if power else '止まっています。'}\")\n",
        "    return True\n",
        "\n",
        "def start_music(energetic: bool, loud: bool, bpm: int) -> str:\n",
        "    \"\"\"指定したパラメーターに合う音楽を再生する。\n",
        "\n",
        "    Args:\n",
        "      energetic: 音楽がエネルギッシュかどうか\n",
        "      loud: 音楽がうるさいかうるさくないか\n",
        "      bpm: 音楽の1分あたりの拍数\n",
        "\n",
        "    Returns: 再生中の曲名。\n",
        "    \"\"\"\n",
        "    print(f\"音楽を再生 {energetic=} {loud=}, {bpm=}\")\n",
        "    return \"Never gonna give you up.\"\n",
        "\n",
        "\n",
        "def dim_lights(brightness: float) -> bool:\n",
        "    \"\"\"照明を落として。\n",
        "\n",
        "    Args:\n",
        "      brightness: ライトの明るさ。0.0はオフ、1.0はフル。\n",
        "    \"\"\"\n",
        "    print(f\"{brightness:.0%}に設定されています\")\n",
        "    return True\n",
        "\n",
        "house_fns = [power_disco_ball, start_music, dim_lights]"
      ],
      "metadata": {
        "id": "5bnHz7g6sC4w"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に、指定されたすべての道具を使用できる命令でモデルを呼び出す。"
      ],
      "metadata": {
        "id": "Q5th4DOztPN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You generally set \"mode\": \"any\" to make sure Gemini actually *uses* the given tools.\n",
        "party_chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config={\n",
        "        \"tools\": house_fns,\n",
        "        \"tool_config\" : {\n",
        "            \"function_calling_config\": {\n",
        "                \"mode\": \"any\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "# Call the API\n",
        "response = party_chat.send_message(\n",
        "    \"Turn this place into a party!\"\n",
        ")\n",
        "\n",
        "\n",
        "print_history(party_chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vsaOJtoutUEL",
        "outputId": "c24e4100-b375-4415-af0a-bbffae7022a9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ディスコボール スピンしています!\n",
            "50%に設定されています\n",
            "音楽を再生 energetic=True loud=True, bpm=120\n",
            "ディスコボール スピンしています!\n",
            "50%に設定されています\n",
            "音楽を再生 energetic=True loud=True, bpm=120\n",
            "ディスコボール スピンしています!\n",
            "50%に設定されています\n",
            "音楽を再生 energetic=True loud=True, bpm=120\n",
            "ディスコボール スピンしています!\n",
            "50%に設定されています\n",
            "音楽を再生 energetic=True loud=True, bpm=120\n",
            "ディスコボール スピンしています!\n",
            "50%に設定されています\n",
            "音楽を再生 energetic=True loud=True, bpm=120\n",
            "ディスコボール スピンしています!\n",
            "50%に設定されています\n",
            "音楽を再生 energetic=True loud=True, bpm=120\n",
            "ディスコボール スピンしています!\n",
            "50%に設定されています\n",
            "音楽を再生 energetic=True loud=True, bpm=120\n",
            "ディスコボール スピンしています!\n",
            "50%に設定されています\n",
            "音楽を再生 energetic=True loud=True, bpm=120\n",
            "ディスコボール スピンしています!\n",
            "50%に設定されています\n",
            "音楽を再生 energetic=True loud=True, bpm=120\n",
            "ディスコボール スピンしています!\n",
            "50%に設定されています\n",
            "音楽を再生 energetic=True loud=True, bpm=120\n",
            "print_history\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Turn this place into a party!"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'power': True} name='power_disco_ball'\n",
            "Functional call: id=None args={'brightness': 0.5} name='dim_lights'\n",
            "Functional call: id=None args={'energetic': True, 'loud': True, 'bpm': 120} name='start_music'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='power_disco_ball' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='dim_lights' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='start_music' response={'result': 'Never gonna give you up.'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'power': True} name='power_disco_ball'\n",
            "Functional call: id=None args={'brightness': 0.5} name='dim_lights'\n",
            "Functional call: id=None args={'loud': True, 'energetic': True, 'bpm': 120} name='start_music'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='power_disco_ball' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='dim_lights' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='start_music' response={'result': 'Never gonna give you up.'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'power': True} name='power_disco_ball'\n",
            "Functional call: id=None args={'brightness': 0.5} name='dim_lights'\n",
            "Functional call: id=None args={'energetic': True, 'loud': True, 'bpm': 120} name='start_music'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='power_disco_ball' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='dim_lights' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='start_music' response={'result': 'Never gonna give you up.'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'power': True} name='power_disco_ball'\n",
            "Functional call: id=None args={'brightness': 0.5} name='dim_lights'\n",
            "Functional call: id=None args={'loud': True, 'energetic': True, 'bpm': 120} name='start_music'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='power_disco_ball' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='dim_lights' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='start_music' response={'result': 'Never gonna give you up.'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'power': True} name='power_disco_ball'\n",
            "Functional call: id=None args={'brightness': 0.5} name='dim_lights'\n",
            "Functional call: id=None args={'bpm': 120, 'loud': True, 'energetic': True} name='start_music'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='power_disco_ball' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='dim_lights' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='start_music' response={'result': 'Never gonna give you up.'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'power': True} name='power_disco_ball'\n",
            "Functional call: id=None args={'brightness': 0.5} name='dim_lights'\n",
            "Functional call: id=None args={'bpm': 120, 'loud': True, 'energetic': True} name='start_music'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='power_disco_ball' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='dim_lights' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='start_music' response={'result': 'Never gonna give you up.'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'power': True} name='power_disco_ball'\n",
            "Functional call: id=None args={'brightness': 0.5} name='dim_lights'\n",
            "Functional call: id=None args={'bpm': 120, 'energetic': True, 'loud': True} name='start_music'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='power_disco_ball' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='dim_lights' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='start_music' response={'result': 'Never gonna give you up.'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'power': True} name='power_disco_ball'\n",
            "Functional call: id=None args={'brightness': 0.5} name='dim_lights'\n",
            "Functional call: id=None args={'energetic': True, 'loud': True, 'bpm': 120} name='start_music'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='power_disco_ball' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='dim_lights' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='start_music' response={'result': 'Never gonna give you up.'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'power': True} name='power_disco_ball'\n",
            "Functional call: id=None args={'brightness': 0.5} name='dim_lights'\n",
            "Functional call: id=None args={'energetic': True, 'bpm': 120, 'loud': True} name='start_music'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='power_disco_ball' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='dim_lights' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='start_music' response={'result': 'Never gonna give you up.'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'power': True} name='power_disco_ball'\n",
            "Functional call: id=None args={'brightness': 0.5} name='dim_lights'\n",
            "Functional call: id=None args={'bpm': 120, 'loud': True, 'energetic': True} name='start_music'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='power_disco_ball' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='dim_lights' response={'result': True}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='start_music' response={'result': 'Never gonna give you up.'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'power': True} name='power_disco_ball'\n",
            "Functional call: id=None args={'brightness': 0.5} name='dim_lights'\n",
            "Functional call: id=None args={'bpm': 120, 'loud': True, 'energetic': True} name='start_music'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 複合的なＦｕｎｃｔｉｏｎコール\n",
        "\n",
        "このモデルは、複数のターンにわたって関数呼び出しを連鎖させることができ、1つの呼び出しの結果を次の呼び出しに反映させることができる。これにより、複雑な複数ステップの推論とタスクの完了が可能になります。\n",
        "\n",
        "**例 特定の映画の上映時間を見つける**\n",
        "\n",
        "theater_functionsを再利用し、より複雑なクエリを実行してみましょう。"
      ],
      "metadata": {
        "id": "q2xeobSntvLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(\n",
        "    model = MODEL_ID,\n",
        "    config = {\n",
        "        \"tools\": theater_functions,\n",
        "    }\n",
        ")\n",
        "\n",
        "response = chat.send_message(\"\"\"\n",
        "  2025年01月01日にカリフォルニア州マウンテンビューで上映されるコメディ映画を検索。\n",
        "  まず、映画のタイトルを見つけます。\n",
        "  次に、それらの映画を上映している映画館を探します。\n",
        "  最後に、各映画館の上映時間を検索します。\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)\n",
        "print(\"\\n--- History ---\")\n",
        "print_history(chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f5X3FoWvu3Uc",
        "outputId": "eaaea5d9-2f73-4845-ec07-662e78e5a553"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025年1月1日にカリフォルニア州マウンテンビューで上映されるコメディ映画の上映時間を検索しました。\n",
            "\n",
            "**映画:**\n",
            "\n",
            "*   **Barbie**\n",
            "    *   Googleplex 16: 10:00, 11:00\n",
            "    *   Android Theatre: 10:00, 11:00\n",
            "*   **Oppenheimer** (注: この映画は通常コメディとは見なされませんが、検索結果に含まれていました。)\n",
            "    *   Googleplex 16: 10:00, 11:00\n",
            "    *   Android Theatre: 10:00, 11:00\n",
            "\n",
            "--- History ---\n",
            "print_history\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n  2025年01月01日にカリフォルニア州マウンテンビューで上映されるコメディ映画を検索。\n  まず、映画のタイトルを見つけます。\n  次に、それらの映画を上映している映画館を探します。\n  最後に、各映画館の上映時間を検索します。\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'description': 'コメディ映画', 'location': 'カリフォルニア州マウンテンビュー'} name='find_movies'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='find_movies' response={'result': ['Barbie', 'Oppenheimer']}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'movie': 'Barbie', 'location': 'カリフォルニア州マウンテンビュー'} name='find_theaters'\n",
            "Functional call: id=None args={'location': 'カリフォルニア州マウンテンビュー', 'movie': 'Oppenheimer'} name='find_theaters'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='find_theaters' response={'result': ['Googleplex 16', 'Android Theatre']}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='find_theaters' response={'result': ['Googleplex 16', 'Android Theatre']}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'location': 'カリフォルニア州マウンテンビュー', 'theater': 'Googleplex 16', 'date': '2025-01-01', 'movie': 'Barbie'} name='get_showtimes'\n",
            "Functional call: id=None args={'location': 'カリフォルニア州マウンテンビュー', 'movie': 'Barbie', 'theater': 'Android Theatre', 'date': '2025-01-01'} name='get_showtimes'\n",
            "Functional call: id=None args={'movie': 'Oppenheimer', 'theater': 'Googleplex 16', 'location': 'カリフォルニア州マウンテンビュー', 'date': '2025-01-01'} name='get_showtimes'\n",
            "Functional call: id=None args={'theater': 'Android Theatre', 'date': '2025-01-01', 'movie': 'Oppenheimer', 'location': 'カリフォルニア州マウンテンビュー'} name='get_showtimes'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='get_showtimes' response={'result': ['10:00', '11:00']}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='get_showtimes' response={'result': ['10:00', '11:00']}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='get_showtimes' response={'result': ['10:00', '11:00']}\n",
            "Function response: will_continue=None scheduling=None parts=None id=None name='get_showtimes' response={'result': ['10:00', '11:00']}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "2025年1月1日にカリフォルニア州マウンテンビューで上映されるコメディ映画の上映時間を検索しました。\n\n**映画:**\n\n*   **Barbie**\n    *   Googleplex 16: 10:00, 11:00\n    *   Android Theatre: 10:00, 11:00\n*   **Oppenheimer** (注: この映画は通常コメディとは見なされませんが、検索結果に含まれていました。)\n    *   Googleplex 16: 10:00, 11:00\n    *   Android Theatre: 10:00, 11:00"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでは、モデルがあなたの質問に答えるために7回の呼び出しを行い、その出力をその後の呼び出しと最終的な答えに使用していることがわかります。\n",
        "\n",
        "## モードを使用したFunctionコール設定\n",
        "\n",
        "AUTOモード（またはSDKのデフォルトの自動実行）で十分な場合が多いですが、モデル/チャットの初期化中またはsend_messageでtool_configパラメータを使用することで、モデルがいつどの関数を呼び出すかを正確に制御することができます。\n",
        "\n",
        "**tool_config**は、FunctionCallingConfigを含むToolConfigオブジェクトを受け入れます。\n",
        "\n",
        "**FunctionCallingConfig**には2つの主要なフィールドがあります：\n",
        "\n",
        "* mode： モード：全体的な関数呼び出し動作を制御します（AUTO、ANY、NONE）。\n",
        "\n",
        "* allowed_function_names： このターンでモデルが呼び出すことを制限される関数名のオプションのリスト。\n",
        "\n",
        "## AUTO (デフォルトモード)\n",
        "* Behavior： モデルはテキストで応答するか、提供されたツールから1つ以上の関数を呼び出すかを決定します。これは最も柔軟なモードです。\n",
        "\n",
        "* SDKデフォルト： 自動実行を有効にしてChatSessionを使用する場合、tool_configで上書きされない限り、基本的な動作は実質的にAUTOモードを使用します。"
      ],
      "metadata": {
        "id": "IUN_Po_TvSk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(model=MODEL_ID)\n",
        "\n",
        "response = chat.send_message(\n",
        "    message=\"Turn on the lights!\",\n",
        "    config={\n",
        "        \"system_instruction\": instruction,\n",
        "        \"tools\": light_controls,\n",
        "        \"tool_config\" : types.ToolConfig(\n",
        "            function_calling_config=types.FunctionCallingConfig(\n",
        "                mode=\"auto\"\n",
        "            )\n",
        "        )\n",
        "    }\n",
        ")\n",
        "\n",
        "print_history(chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "eqNP2i5uv2qi",
        "outputId": "972a1b17-e1e3-447d-c571-8cf068f246a3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIGHTBOT: Lights enabled.\n",
            "print_history\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Turn on the lights!"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={} name='enable_lights'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='enable_lights' response={'result': None}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "承知いたしました。照明を点灯します。"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NONE モード\n",
        "\n",
        "Behavior： たとえツールが提供されていたとしても、モデルが関数を呼び出すことは明示的に禁止されている。テキストのみで応答する。純粋に会話のような反応が欲しいターンに便利。\n",
        "\n"
      ],
      "metadata": {
        "id": "-KIipxpJwBY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "none_chat = client.chats.create(model=MODEL_ID)\n",
        "\n",
        "response = none_chat.send_message(\n",
        "    message=\"Hello light-bot, what can you do?\",\n",
        "    config={\n",
        "        \"system_instruction\": instruction,\n",
        "        \"tools\": light_controls, # Tools are provided\n",
        "        \"tool_config\" : types.ToolConfig(\n",
        "            function_calling_config=types.FunctionCallingConfig(\n",
        "                mode=\"none\"\n",
        "            )\n",
        "        ) # but NONE mode prevents their use\n",
        "    }\n",
        ")\n",
        "\n",
        "print_history(none_chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bLjJKFjLwUVT",
        "outputId": "07b0bed0-641c-41ee-fb63-05ca38b5a043"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "print_history\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hello light-bot, what can you do?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "こんにちは。私は照明を点灯したり消灯したりできます。そして、照明の色も設定できます。"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "syLDVaaswQ4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANYモード\n",
        "\n",
        "* Behavior： モデルに少なくとも1つの関数を呼び出させます。\n",
        "\n",
        "  * allowed_function_namesが設定されている場合、モデルはそのリストから1つ以上の関数を選択しなければなりません。\n",
        "\n",
        "  * allowed_function_namesが設定されていない場合、モデルは完全なツールリストから1つ以上の関数を選択しなければなりません。\n",
        "\n",
        "* 関数の自動呼び出しが有効な場合、SDKはmax_remote_calls（デフォルト：10）に達するまで関数を自動的に呼び出します。\n",
        "\n",
        "* x回の自動関数呼び出しを許可するには、max_remote_callsをx + 1に設定します。もっと読む\n",
        "\n",
        "* 使用例 アプリケーションの状態によって、次のステップで特定のアクションを実行する必要がある場合に便利です。"
      ],
      "metadata": {
        "id": "-oSrzMRiwZJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(model=MODEL_ID)\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Make this place PURPLE!\",\n",
        "    config={\n",
        "        \"system_instruction\": instruction,\n",
        "        \"tools\": light_controls, # Provide all tools\n",
        "        \"tool_config\" : {\n",
        "            \"function_calling_config\": {\n",
        "                \"mode\": \"any\"\n",
        "            }\n",
        "        },\n",
        "        \"automatic_function_calling\": {\n",
        "            \"maximum_remote_calls\" : 1\n",
        "        }\n",
        "      } # But restrict to available_fns with ANY mode\n",
        ")\n",
        "\n",
        "print_history(chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "qwSXtUq1woa0",
        "outputId": "5408823d-377a-452d-c796-0b06f2d65399"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIGHTBOT: Lights set to #800080\n",
            "print_history\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Make this place PURPLE!"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'rgb_hex': '#800080'} name='set_light_color'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: will_continue=None scheduling=None parts=None id=None name='set_light_color' response={'result': None}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional call: id=None args={'rgb_hex': '#800080'} name='set_light_color'\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}